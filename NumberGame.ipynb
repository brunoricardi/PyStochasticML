{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explores **Bayesian concept learning**. It is based on Ref. *Machine Learning : A Probabilistic Perspective*, by Kevin P. Murphy, 2012, ISBN 978-0-262-01802-9, pp. 65-71."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "A good example of concept learning is how we human beings learn language when we are children. It is scientifically known that it happens by positive learning. Consider the word \"dog\". The way we associate the animal that we see to this word is by being told that, when we face an instance of such animal, we are seing a dog. Usually this is done by parents: \"this is a dog\", or \"look at the dog\". It is intuitive to notice that negative learning, even though can bring information, is not as effective to learn a certain concept. Being told that \"this is not a dog\" when we see a cat is not very helpful when we are children. \n",
    "\n",
    "In a more general framework, we think of input data $x$ to which is associated an output, or feature $y$. This association is potentially modeled via a set of parameters $\\theta$. There are two questions that we could be interested in. The first one is: given some new data $\\tilde{x}$, what is the probability that it has feature $y = c$ once we have somehow derived the parameters $\\theta$? This would be encoded in the probability distribution $p(y = c | x, \\theta)$. The second, which is going to be important to us here, is: what type of input $x$ gives us a certain output $y = c$? This is the inverse conditional probability which, by Bayes rule, is given by\n",
    "\n",
    "$p(y = c | x,\\theta) \\propto p(x | y=c,\\theta) p(y=c,\\theta)$\n",
    "\n",
    "In the case of concept learning, what we have is a certain concept $C$ and an associated probability distribution $f$ such that $f(x) = 1$ if $x \\in C$ and zero otherwise. We are then interested in learning $f$ for a certain $C$ that we don't necessarily know."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The game\n",
    "Consider a simple arithmetical concept $C$, such as \"prime numbers\". We draw a series $D$ of randomly chosen numbers from $C$. Given $D$, we would like to classify a new number $\\tilde{x}$, *viz.* does it belong to $C$ or not? More generally, what is the **posterior probability distribution** $p(\\tilde{x} | D)$?  \n",
    "\n",
    "### Examples\n",
    "Suppose we do just one draw and I tell you that $D = \\{16\\}$. You could imagine that choices like 17, 32 or 6 -- numbers that are somewhat related to 16 -- are more likely to meet the concept $C$ that we are trying to learn, but at this point the probability distribution should be quite spread all over the possible inputs.\n",
    "\n",
    "Conversely, if I do three more draws and tell you that $D = \\{16, 8, 2, 32\\}$, you could, by **induction**, say that $C$ is the set of numbers that are \"powers of two\", which would lead to a quite more structured distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory\n",
    "\n",
    "### Relevant spaces\n",
    "Let's keep going with the previous example to better define our framework. The \"powers of two\" concept is one of the possibilities that could represent $C$. But there might be many others! All of them live in the **hypothesis space** $H$. For instance, if $h = \\text{odd numbers}$, then $h \\in H$. However, a lot of possibilities that leave in $H$ may not be consistent with our observation $D$. For instance, if again $D = \\{16\\}$, then $h = \\text{odd numbers}$ is definitely wrong! We then define the subspace of possibilities that are consistent with observations as the **version space**.\n",
    "\n",
    "One problem now is that, for a certain observation, multiple possibilities in the version space can be consistent. For instance, for $D = \\{16\\}$, $h_1 = \\text{powers of 2}$ and $h_2 = \\text{even numbers}$ are both valid. How do we decide?\n",
    "\n",
    "### Occam's razor\n",
    "To decide, we could use a certain degree of knowledge. Consider the larger observation $D = \\{16, 8, 2, 32\\}$. If the true concept was $h_2$, how come we only observed numbers that are described by $h_1$? We want to avoid this **suspicious coincidence**.\n",
    "\n",
    "To further develop this idea, we define the **extension** of a concept $h$ as all the instances of $h$ over the interval that is relevant to the problem. For simplicity, let us assume now that we are concerned about integer numbers between 1 and 100. The extension of $h_2$ would then be $\\{2, 4, 6, 8, ..., 98, 100\\}$.  \n",
    "\n",
    "We will be assuming that the examples that are drawn to create $D$ are sampled uniformly at random from the extension of the true concept $C$. This is called a **strong sampling assumption**.\n",
    "\n",
    "The probability of independently sampling $N$ items, with replacement, from a certain $h$ is \n",
    "\n",
    "$p(D | h) = \\left[\\frac{1}{\\text{size}(h)}\\right]^N$.\n",
    "\n",
    "This shows exactly that what we are modeling favors the simplest, or smallest hypothesis that is consistent with the data. This is often refered to as **Occam's razor**, or the **size principle**. \n",
    "\n",
    "### Likelihood\n",
    "To illustrate it, notice that in the case of $D = \\{16\\}$, we have $p(D | h_1) = 1/6$ and $p(D | h_2) = 1/50$. After the other 3 draws that give $D = \\{16, 8, 2, 32\\}$, we have a **likelihood** ratio of almost 5000:1 in favor of $h_1$. \n",
    "\n",
    "\n",
    "### Priors\n",
    "Suppose again that $D = \\{16, 8, 2, 32\\}$. As far as we are concerned about the likelihood, $h_3 = \\text{powers of 2 except 32}$ is even more likely than $h_1$! However, it seems *conceptually unnatural*. This can be captured by assigning a low **prior probability** to such unnatural concepts, and that is how background knowledge and subjectiveness can be brought into the problem (recall we are working with Bayesian probabilities).\n",
    "\n",
    "\n",
    "### Posteriors\n",
    "The *a posteriori* probability, which is the one that we get after obtaining the information brought by $D$, is, by Bayes rule, the likelihood times the prior, normalized:\n",
    "\n",
    "$p(h | D) = \\frac{p(D | h) p(h)}{\\sum_{h'\\in H} p(D,h')}$,\n",
    "\n",
    "and notice that \n",
    "\n",
    "$p(D|h) = \\mathbb{I}(D \\in h) / |h|^N$,\n",
    "\n",
    "where $\\mathbb{I}(D \\in h)$ is 1 if, and only if, all of the data is in the extension of hypothesis $h$ and $|h|$ is the size of $h$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
